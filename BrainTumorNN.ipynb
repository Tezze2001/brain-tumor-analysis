{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.15.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (21.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow-intel==2.15.0->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tomma\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: There was an error checking the latest version of pip.\n"
          ]
        }
      ],
      "source": [
        "! pip install keras\n",
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2FwU-9whW2T"
      },
      "source": [
        "Fonte: [Brain Tumor Dataset](https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQrCxXbnkoFu"
      },
      "source": [
        "**N.B.**: la parte degli iperparametri è attualmente commentata in quanto è richiesto molto tempo, da rimovere per la consegna."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMDAmeONlXwc"
      },
      "source": [
        "# Appunti per la creazione della rete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1magt7dOlcMb"
      },
      "source": [
        "- **Dense**: implements the operation:\n",
        "```\n",
        "output = activation(dot(input, kernel) + bias)\n",
        "```\n",
        "where activation is the element-wise activation function passed as the activation argument\n",
        "- **Bainary Cross Entropy**: computes the cross-entropy loss between true labels and predicted labels.\n",
        "Use this cross-entropy loss for binary (0 or 1) classification applications. The loss function requires the following inputs:\n",
        " - y_true (true label): This is either 0 or 1.\n",
        " - y_pred (predicted value): This is the model's prediction, i.e, a single floating-point value which either represents a logit, (i.e, value in [-inf, inf] when from_logits=True) or a probability (i.e, value in [0., 1.] when from_logits=False).\n",
        "- **SGD**: Gradient descent (with momentum) optimizer.\n",
        "- **ADAM**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzJnIjmKhhFV"
      },
      "source": [
        "# Rete Neurale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_Kpwh1QiBUl",
        "outputId": "dc0b51af-fdc5-44c7-8144-5e3345b22827"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "# Esecuzione in remoto\n",
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount('/content/drive/')\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wY887H8cPhWt"
      },
      "outputs": [],
      "source": [
        "# Esecuzione in locale\n",
        "path_to_dataset = './Dataset/Brain Tumor.csv'\n",
        "path_to_hyperparameter = \"./\" + \"NN_Hyperparameters.json\"\n",
        "path_for_json = \"./NN_Hyperparameters\"\n",
        "\n",
        "# Esecuzione in remoto\n",
        "# path_to_dataset = '/content/drive/MyDrive/Magistrale/Machine Learning/Progetto/Brain Tumor.csv'\n",
        "# path_to_hyperparameter = \"/content/drive/MyDrive/Magistrale/Machine Learning/\" + \"NN_Hyperparameters.json\"\n",
        "# path_for_json = \"/content/drive/MyDrive/Magistrale/Machine Learning/NN_Hyperparameters\"    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IJqwp_raiKW6"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(path_to_dataset, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssvCLwF7hjhj"
      },
      "source": [
        "## Preprocessing del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4XrifFSiq82",
        "outputId": "4ee8406f-2bbc-438c-bc28-886a9b8894c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class                   int64\n",
              "Mean                  float64\n",
              "Variance              float64\n",
              "Standard Deviation    float64\n",
              "Entropy               float64\n",
              "Skewness              float64\n",
              "Kurtosis              float64\n",
              "Contrast              float64\n",
              "Energy                float64\n",
              "ASM                   float64\n",
              "Homogeneity           float64\n",
              "Dissimilarity         float64\n",
              "Correlation           float64\n",
              "Coarseness            float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "m-djPxAniNHQ",
        "outputId": "ad4a9c3a-d7df-4b15-fc30-a59770e7d930"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Skewness</th>\n",
              "      <th>Contrast</th>\n",
              "      <th>Correlation</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Image1</th>\n",
              "      <td>6.535339</td>\n",
              "      <td>0.109059</td>\n",
              "      <td>4.276477</td>\n",
              "      <td>98.613971</td>\n",
              "      <td>0.981939</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image2</th>\n",
              "      <td>8.749969</td>\n",
              "      <td>0.266538</td>\n",
              "      <td>3.718116</td>\n",
              "      <td>63.858816</td>\n",
              "      <td>0.988834</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image3</th>\n",
              "      <td>7.341095</td>\n",
              "      <td>0.001467</td>\n",
              "      <td>5.061750</td>\n",
              "      <td>81.867206</td>\n",
              "      <td>0.978014</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image4</th>\n",
              "      <td>5.958145</td>\n",
              "      <td>0.001477</td>\n",
              "      <td>5.677977</td>\n",
              "      <td>151.229741</td>\n",
              "      <td>0.964189</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image5</th>\n",
              "      <td>7.315231</td>\n",
              "      <td>0.146761</td>\n",
              "      <td>4.283221</td>\n",
              "      <td>174.988756</td>\n",
              "      <td>0.972789</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Mean   Entropy  Skewness    Contrast  Correlation Class\n",
              "Image                                                              \n",
              "Image1  6.535339  0.109059  4.276477   98.613971     0.981939     0\n",
              "Image2  8.749969  0.266538  3.718116   63.858816     0.988834     0\n",
              "Image3  7.341095  0.001467  5.061750   81.867206     0.978014     1\n",
              "Image4  5.958145  0.001477  5.677977  151.229741     0.964189     1\n",
              "Image5  7.315231  0.146761  4.283221  174.988756     0.972789     0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Trasformo la variabile target in una variabile categorica\n",
        "dataset[\"Class\"] = dataset[\"Class\"].astype(\"category\")\n",
        "\n",
        "# Dalle analisi precedenti abbiamo deciso di utilizzare questi attributi per addestrare il nostro modello\n",
        "dataset = dataset[['Mean', 'Entropy', 'Skewness', 'Contrast', 'Correlation', 'Class']]\n",
        "\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "90b51Ekojkll"
      },
      "outputs": [],
      "source": [
        "y = dataset['Class']\n",
        "X = dataset.drop(['Class'], axis=1)\n",
        "\n",
        "columns_name = X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JBOuSCZjRgL"
      },
      "source": [
        "Per le reti neurali risulta utile standardizzare i dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "zOYrZRTljW7X",
        "outputId": "42dea672-4c1b-444e-c1af-e415ee866e93"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Entropy</th>\n",
              "      <th>Skewness</th>\n",
              "      <th>Contrast</th>\n",
              "      <th>Correlation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Image1</th>\n",
              "      <td>-0.515700</td>\n",
              "      <td>0.504650</td>\n",
              "      <td>0.067855</td>\n",
              "      <td>-0.268050</td>\n",
              "      <td>1.000713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image2</th>\n",
              "      <td>-0.129018</td>\n",
              "      <td>2.746050</td>\n",
              "      <td>-0.150204</td>\n",
              "      <td>-0.585492</td>\n",
              "      <td>1.264377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image3</th>\n",
              "      <td>-0.375013</td>\n",
              "      <td>-1.026708</td>\n",
              "      <td>0.374531</td>\n",
              "      <td>-0.421010</td>\n",
              "      <td>0.850636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image4</th>\n",
              "      <td>-0.616481</td>\n",
              "      <td>-1.026561</td>\n",
              "      <td>0.615188</td>\n",
              "      <td>0.212525</td>\n",
              "      <td>0.322041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Image5</th>\n",
              "      <td>-0.379529</td>\n",
              "      <td>1.041256</td>\n",
              "      <td>0.070489</td>\n",
              "      <td>0.429532</td>\n",
              "      <td>0.650854</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Mean   Entropy  Skewness  Contrast  Correlation\n",
              "Image                                                      \n",
              "Image1 -0.515700  0.504650  0.067855 -0.268050     1.000713\n",
              "Image2 -0.129018  2.746050 -0.150204 -0.585492     1.264377\n",
              "Image3 -0.375013 -1.026708  0.374531 -0.421010     0.850636\n",
              "Image4 -0.616481 -1.026561  0.615188  0.212525     0.322041\n",
              "Image5 -0.379529  1.041256  0.070489  0.429532     0.650854"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X[columns_name] = scaler.fit_transform(X)\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDCcwgZpjtQU"
      },
      "source": [
        "Suddividiamo ora i dati in Train e Test, abbiamo scelto di utilizzare l'80% dei\n",
        "dati per il training e il restante 20% per il test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Bum3wX9Wj6-W"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y93g54BYkJhQ"
      },
      "source": [
        "Per evitare di introdurre errori nell'addestramento della rete abbiamo voluto\n",
        "verificare che il dataset dopo lo split fosse ancora bilanciato"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTy1DpbskIsM",
        "outputId": "f0a97bc9-eaf2-40de-d65e-dfff558a9f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset:\n",
            "\t-Negative 55.26 %\n",
            "\t-Positive 44.74 %\n",
            "Train data:\n",
            "\t- Negative 55.27 %\n",
            "\t- Positive 44.73 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset:\\n\\t-Negative\", round((y.value_counts()[0]/y.shape[0]) * 100, 2),\n",
        "      \"%\\n\\t-Positive\", round((y.value_counts()[1]/y.shape[0]) * 100, 2), \"%\")\n",
        "print(\"Train data:\\n\\t- Negative\", round((y_train.value_counts()[0] / y_train.shape[0]) * 100, 2),\n",
        "      \"%\\n\\t- Positive\", round((y_train.value_counts()[1] / y_train.shape[0]) * 100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1rQNVCBhoFO"
      },
      "source": [
        "## Ricerca degli iperparametri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mNk6Sjpjk9F9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\tomma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from itertools import product"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6O3JLYoxlET3"
      },
      "outputs": [],
      "source": [
        "def create_model(units=[6, 6], activation='relu', opt='adam', metric='accuracy', input_layer_size=5):\n",
        "  # Creazione del modello\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(units=units[0], input_shape=(input_layer_size,), activation=activation))\n",
        "\n",
        "  if len(units) >= 2 and units[1] != 0:\n",
        "    model.add(Dense(units=units[1], activation=activation))\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[metric])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar7SZlIxmJIh"
      },
      "source": [
        "Parametri tra cui cercare la combinazione migliore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0X4BSiZmP0_",
        "outputId": "3e5858f6-7248-474f-a122-7d193dc64c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total combinations: 432\n"
          ]
        }
      ],
      "source": [
        "units = [0, 5, 10, 50]\n",
        "activation = ['sigmoid', 'relu', 'leaky_relu']\n",
        "optimizer = ['sgd', 'adam']\n",
        "batch_size = [50, 100, 300]\n",
        "epochs = [100, 300]\n",
        "\n",
        "param_combinations = list(product(units, units, activation, optimizer, batch_size, epochs))\n",
        "\n",
        "list_index_remove = []\n",
        "\n",
        "for i, params in enumerate(param_combinations):\n",
        "  if params[0] == 0:\n",
        "    list_index_remove.append(params)\n",
        "\n",
        "for to_remove in list_index_remove:\n",
        "  param_combinations.remove(to_remove)\n",
        "\n",
        "print(\"Total combinations:\", len(param_combinations))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qUMBEkmup7kn"
      },
      "outputs": [],
      "source": [
        "X_cross_val = pd.DataFrame(data = X_train, columns = columns_name)\n",
        "Y_cross_val = pd.DataFrame(data = y_train, columns = ['Class'])\n",
        "\n",
        "Y_cross_val = (Y_cross_val.reset_index()).drop(['Image'], axis=1)\n",
        "X_cross_val = (X_cross_val.reset_index()).drop(['Image'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AoHrkF_-qB9R"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "import scipy.stats as st\n",
        "import numpy as np\n",
        "import time\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "iNoTsNkgqF08",
        "outputId": "92c76cc6-2c86-4122-f7f8-9b01ac48e6d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/432 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\tomma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\tomma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\tomma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\tomma\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 255/432 [3:29:12<2:10:58, 44.40s/it] "
          ]
        }
      ],
      "source": [
        "k = 5 # Number of folds\n",
        "skf = StratifiedKFold(n_splits=k, shuffle=True)\n",
        "\n",
        "# Create a history of model train\n",
        "performance = dict()\n",
        "\n",
        "# Iterate over combination\n",
        "for i, (u1, u2, act, opt, batch, ep) in enumerate(tqdm(param_combinations)):\n",
        "  # Setup dictornary\n",
        "  performance[i] = dict()\n",
        "  performance[i]['param'] = ([u1, u2], act, opt, batch, ep)\n",
        "  performance[i]['results'] = []\n",
        "  performance[i]['time'] = []\n",
        "\n",
        "  # Create model\n",
        "  model = create_model(units=[u1, u2], activation=act, opt=opt)\n",
        "\n",
        "  # Train model\n",
        "  for train_idx, test_idx in skf.split(X_cross_val, Y_cross_val):\n",
        "    X_val_train, X_val_test = X_cross_val[X_cross_val.index.isin(train_idx)], X_cross_val[X_cross_val.index.isin(test_idx)]\n",
        "    y_val_train, y_val_test = Y_cross_val[Y_cross_val.index.isin(train_idx)], Y_cross_val[Y_cross_val.index.isin(test_idx)]\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    model.fit(X_val_train, y_val_train, epochs=ep, batch_size=batch, verbose=0)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    score = model.evaluate(X_val_test, y_val_test, verbose=0)\n",
        "    performance[i]['results'].append(score[1])\n",
        "    performance[i]['time'].append(end - start)\n",
        "\n",
        "  accuracy_score = performance[i]['results']\n",
        "  performance[i]['interval90'] = st.t.interval(confidence=0.90, df=len(accuracy_score)-1, loc=np.mean(accuracy_score), scale=st.sem(accuracy_score))\n",
        "  performance[i]['interval95'] = st.t.interval(confidence=0.95, df=len(accuracy_score)-1, loc=np.mean(accuracy_score), scale=st.sem(accuracy_score))\n",
        "  performance[i]['meanTime'] = sum(performance[i]['time']) / len(performance[i]['time'])\n",
        "  performance[i]['meanAccuracy'] = sum(accuracy_score) / len(accuracy_score)\n",
        "\n",
        "  if int(i) % 100 == 0 and int(i) != 0:\n",
        "    with open(str(path_for_json + str(int(i / 100)) + \".json\"), \"w\") as outfile:\n",
        "      json.dump(performance, outfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JzSceLkrMyy"
      },
      "source": [
        "Analisi dei risultati ottenuti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAtH-17OruOa"
      },
      "outputs": [],
      "source": [
        "dict_keys = list(performance.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j6YXjpErPOr"
      },
      "outputs": [],
      "source": [
        "performance_interval90 = dict()\n",
        "performance_interval95 = dict()\n",
        "performance_time = dict()\n",
        "performance_acc = dict()\n",
        "\n",
        "for key in dict_keys:\n",
        "  interval90 = performance[key]['interval90']\n",
        "  interval95 = performance[key]['interval90']\n",
        "\n",
        "  performance_interval90[key] = interval90[1] - interval90[0]\n",
        "  performance_interval95[key] = interval95[1] - interval95[0]\n",
        "  performance_time[key] = performance[key]['meanTime']\n",
        "  performance_acc[key] = performance[key]['meanAccuracy']\n",
        "\n",
        "performance_interval90 = sorted(performance_interval90.items(), key=lambda x:x[1])\n",
        "performance_interval95 = sorted(performance_interval95.items(), key=lambda x:x[1])\n",
        "performance_time = sorted(performance_time.items(), key=lambda x:x[1])\n",
        "performance_acc = sorted(performance_acc.items(), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "sorted_dict = dict()\n",
        "\n",
        "for i, (index, _) in enumerate(performance_interval90):\n",
        "  sorted_dict[index] = dict()\n",
        "  sorted_dict[index]['90'] = i + 1\n",
        "\n",
        "for i, (index, _) in enumerate(performance_interval95):\n",
        "  sorted_dict[index]['95'] = i + 1\n",
        "\n",
        "for i, (index, _) in enumerate(performance_time):\n",
        "  sorted_dict[index]['time'] = i + 1\n",
        "\n",
        "for i, (index, _) in enumerate(performance_acc):\n",
        "  sorted_dict[index]['acc'] = i + 1\n",
        "\n",
        "dataframe_model = pd.DataFrame(sorted_dict)\n",
        "dataframe_model = dataframe_model.T\n",
        "\n",
        "weights = pd.Series([1, 1, 2, 2], index=dataframe_model.columns)\n",
        "\n",
        "dataframe_model['Total'] = (dataframe_model * weights).sum(axis=1)\n",
        "dataframe_model = dataframe_model.sort_values(by=['Total'])\n",
        "\n",
        "best_model_index = dataframe_model.index[0]\n",
        "best_model = performance[best_model_index]['param']\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ3Ut5TzsH0u"
      },
      "source": [
        "Rappresentazione dei risultati ottenuti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBa10ikFsKpo"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(dataframe_model, x='time', y='acc')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-FuEwi6hs87"
      },
      "source": [
        "## Addestramento del modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEAwHcLPskLd"
      },
      "outputs": [],
      "source": [
        "# Create the best model\n",
        "model = create_model(units=best_model[0], activation=best_model[1], opt=best_model[2], input_layer_size=X_train.shape[1])\n",
        "\n",
        "# Addestrament del modello\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=best_model[3], verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhvCg_xVhvZp"
      },
      "source": [
        "## Valutazione del modello"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lseFv7fGtABb"
      },
      "source": [
        "Valutazione del modello attraverso le metriche fornite da Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOZYeAlms-1f"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIj2GQEqtDtG"
      },
      "source": [
        "Valutazione del modello utilizzando altre metriche"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZm3LuWshES1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGf5jybItMcC"
      },
      "source": [
        "Definizione di una funzione per associare un etichetta ai risultati della rete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLJhZqwTtGwe"
      },
      "outputs": [],
      "source": [
        "def my_predict(model, X_test, threshold=0.5):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.where(y_pred > threshold, 1, 0).flatten()\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6w_OvN7jtSLH"
      },
      "outputs": [],
      "source": [
        "# Valutazione del modello utilizzando i dati di test\n",
        "y_pred = my_predict(model, X_test, 0.3)\n",
        "\n",
        "accuracy_train_test = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Stampa le prestazioni del modello\n",
        "print('Accuracy:', accuracy_train_test)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1-score:', f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIGQ7-WDtekk"
      },
      "source": [
        "Calcolo della matrice di confusione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8PsoxNxthGb"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Negative', 'Positive'])\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shLIXg66tsDJ"
      },
      "source": [
        "Report della classificazione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEhbGJ45ttkM"
      },
      "outputs": [],
      "source": [
        "classification_report(y_pred, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40LWfEpntvbd"
      },
      "source": [
        "Calcolo e disegno della curva ROC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVeSqOsdtxfi"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "y_pred_prob = model.predict(X_test).ravel()\n",
        "\n",
        "# Calcola la curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "\n",
        "# Calcola l'AUC della curva ROC\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "# Disegna la curva ROC\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlim([-0.01, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGiDxr3tt0_g"
      },
      "source": [
        "### Valutazione del modello attraverso 10-fold validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ8_legft5X4"
      },
      "outputs": [],
      "source": [
        "n_fold = 10\n",
        "folds = StratifiedKFold(n_splits=n_fold, shuffle=True)\n",
        "\n",
        "accuracy_stratified = []\n",
        "\n",
        "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "  X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "  y_train, y_valid = y[train_idx], y[valid_idx]\n",
        "  model = create_model(units=best_model[0], activation=best_model[1], opt=best_model[2], input_layer_size=X_train.shape[1])\n",
        "  model.fit(X_train, y_train, epochs=best_model[4], batch_size=best_model[3], verbose=0)\n",
        "  y_pred_valid = my_predict(model, X_valid)\n",
        "  accuracy_stratified.append(accuracy_score(y_valid, y_pred_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlRKYZeRuKD5"
      },
      "source": [
        "Calcolo dell'intervallo di confidenza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lHNXXrauMQx"
      },
      "outputs": [],
      "source": [
        "st.t.interval(confidence=0.90, df=len(accuracy_stratified)-1, loc=np.mean(accuracy_stratified), scale=st.sem(accuracy_stratified))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBAyAxnlwQtf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "# Calculate mean and confidence interval on k-fold\n",
        "mean_value = np.mean(accuracy_stratified)\n",
        "confidence_interval = stats.t.interval(0.95, len(accuracy_stratified)-1, loc=np.mean(accuracy_stratified), scale=stats.sem(accuracy_stratified))\n",
        "\n",
        "# Plot the mean and confidence interval\n",
        "plt.errorbar(0, mean_value, yerr=(confidence_interval[1] - confidence_interval[0])/2, fmt='o', label='K-fold')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Mean with Confidence Interval')\n",
        "\n",
        "# Show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

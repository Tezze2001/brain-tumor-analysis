\chapter{Introduzione}

Questo è un progetto per l'esame di Machine Learning del primo anno del corso 
di laurea magistrale in informatica dell'Università degli Studi di Milano-Bicocca.

L'intero progetto si basa sul riconoscimento della presenza di un tumore al cervello
data l'immagine di una risonanza magnetica.

Il dataset scelto per questo progetto è scaricabile dal seguente 
\href{https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor/data}{link} ed è
composto da un insieme di features estratte dalle immagini ottenute dalle risonanze 
magnetiche del cervello di diversi pazienti.

Per il riconoscimento del tumore sono stati allenati i seguenti modelli di machine
learning:
\begin{itemize}
    \item \textbf{SVM}: è stato scelto questo modello vista la buona capacità
    teorica nel generalizzare.
    \item \textbf{Gaussian Naive Bayes}: è stato scelto questo modello dal momento
    che permette di modellare le probabilità esplicitamente.
    % TODO: anche la rete neurale e SVM possono essere probabilistica
    \item \textbf{Rete neurale}: è stato scelto questo modello per confrontare 
    i primi due con una soluzione neurale.
\end{itemize}

L'obiettivo sarà quello di trovare il modello migliore che riduca al minimo i falsi 
negativi, mantenendo comunque una buona precisione sui veri negativi. Per la ricerca
sono state effettuate le seguenti operazioni:
\begin{itemize}
    \item \textbf{Analisi esplorativa dei dati}: studio esplorativo del dataset
    utile per effettuare le prime osservazioni sui dati
    \item \textbf{Riduzione di dimensionalità e preprocessing del dataset}: 
    applicazione di diverse trasformazioni del dataset, dalla rimozione dei duplicati,
    fino alla rimozione dei valori costanti. In aggiunta è stata ridotta la dimensionalità
    utilizzando due metodi, il primo basato sulla rimozione delle features correlate,
    il secondo basato sull'utilizzo di pca. In questa fase vengono quindi generati 
    i due dataset.
    \item \textbf{Apprendimento dei modelli}: sono stati allenati i tre diversi modelli
    sull'$80\%$ delle istanze dei relativi dataset per confrontare qual è la metodologia 
    migliore per ridurre la dimensionalità. Prima di effettuare l'apprendimento
    vengono anche effettuate tutte le operazioni di ricerca degli iperparamentri 
    migliori per ciascun modello.
    \item \textbf{Valutazione dei modelli}: una volta trovati gli iperparametri
    migliori ed effettuata l'operazione di apprendimento, sono state effettuate
    tutte le operazioni di valutazione dei modelli sul $20\%$ di istanze rimanenti
    di entrambi i dataset.
    \item \textbf{Valutazione della robustezza}: dal momento che il dataset è
    di medie dimensioni allora è stata effettuata una cross-validation per 
    accertarsi che le osservazioni indotte dalla fase precedente fossero affidabili.
    \item \textbf{Confronto tra i vari modelli}: sono stati confrontati tutti
    i modelli sia in merito ai criteri di valutazione, sia in merito ai tempi 
    di apprendimento.
\end{itemize}

In conclusione, la struttura dell'elaborato è delineata dai seguenti capitoli:
\begin{itemize}
    \item \textbf{Introduzione}: descrizione del dominio e presentazione dei modelli che 
    verranno presi in considerazione per questo progetto.
    \item \textbf{Dataset}: descrizione di come è stato costruito il dataset a partire
    dalle immagini, ovvero come sono state ricavate le features, e analisi esplorativa.
    \item \textbf{Rete neurale}: descrizione e analisi delle performance della rete.
    \item \textbf{SVM}: descrizione e analisi delle performance delle SVM.
    \item \textbf{Gaussian Naive Bayes}: descrizione e analisi delle performance 
    per Gaussian Naive Bayes.
    \item \textbf{Analisi dei risultati}: analisi comparata dei risultati tra i 
    tre modelli considerati.
    \item \textbf{Conclusioni}: conclusioni sull'elaborato.
\end{itemize}